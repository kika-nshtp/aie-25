# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`.
- Размер: 12000 строк, 30 столбцов.
- Целевая переменная: `target` - классы 0 и 1 с распределением 0.676583 и 0.323417 соответственно.
- Признаки: столбец target - бинарная классификация, умеренный дисбаланс.
Есть несколько "числовых" полей: столбцы с num01 по num24, есть несколько "категориальных-подобных" полей: с cat_contract по tenure_months.

## 2. Protocol

- Разбиение: train 0.75 к test 0.25 (доли), `random_state` = 42
- Подбор: CV - кросс-валидация на train: нужна для подбора гиперпараметров без доступа к тесту. В работе было 5 фолдов. С помощью оценки cv проводилась оптимизация моделей.
- Метрики: accuracy, F1, ROC-AUC. Нсть наличие вероятностей, поэтому уместно использлвание этих метрик.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline): помогает понять, что модель вообще умеет что-то лучше «угадайки». Выполняется без подбора.
- LogisticRegression (baseline из S05): логрегрессия почти всегда требует масштабирования признаков, поэтому используем Pipeline со StandardScaler. Выполняется с минимальным подбором. Подбиралось C (обратная сила регуляризации): меньше C -> сильнее регуляризация -> проще модель.
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`): одна модель дерева решений. Что обычно делает дерево “сложнее” и склоннее к переобучению: большой max_depth, маленький min_samples_leaf, ccp_alpha – параметр cost-complexity pruning (штраф за сложность). В задании использовали все перечисленные параметры сложности. Подбор выполнялся при помощи выведенной ранее единой функции для подбора гиперпараметров через GridSearchCV.
- RandomForestClassifier: ансамбль деревьев (bagging). Идеи: много деревьев (n_estimators) снижает дисперсию, max_features добавляет разнообразие деревьев (важно для ансамблей), ограничения глубины/листа помогают контролировать переобучение. Подбор выполнялся при помощи выведенной ранее единой функции для подбора гиперпараметров через GridSearchCV.
- HistGradientBoosting: градиентный бустинг по гистограммам (быстро и часто качественно). Ключевые “ручки”: learning_rate - шаг обучения (меньше -> аккуратнее, часто нужно больше итераций), max_depth и max_leaf_nodes - сложность базовых деревьев, early_stopping=True включает остановку по внутренней валидации на train. Подбор выполнялся при помощи выведенной ранее единой функции для подбора гиперпараметров через GridSearchCV.

Опционально:

- StackingClassifier (с CV-логикой): ансамбль из нескольких уже обученных моделей + метамодель. Использовалось: estimators - базовые модели (их предсказания идут на вход метамодели),  final_estimator - метамодель (здесь логистическая регрессия), cv=5: CV внутри стекинга, чтобы метамодель училась без утечки. Стекинг обычно имеет мало “ручек”, поэтому без GridSearch – просто честная оценка.

## 4. Results

- Сохранение артефактов эксперимента в artifacts/. После выполнения этой ячейки можно открыть папку artifacts/ и увидеть: metrics_test.json (итоговые метрики), search_summaries.json (лучшие параметры подбора).
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение. Выбор “лучшей” модели по таблице результатов: ('HistGradientBoosting',
 {'accuracy': 0.9363333333333334,
  'f1': 0.8982418753329782,
  'roc_auc': 0.9746823421867858,
  'model': 'HistGradientBoosting'})
  Диагностика на тесте: confusion matrix и ROC-кривая. Confusion matrix помогает понять тип ошибок (FP/FN), ROC показывает качество ранжирования вероятностей по всем порогам. Сохранение артефактов эксперимента в artifacts/figures/.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко. В начале работы мы фиксируем RANDOM_STATE, чтобы случайные компоненты были воспроизводимыми. При изменении `random_state` будет необходимо перезапустить обучение для каждой модели. В противном случае у моделей будут отличаться данные, необходимые для опоры на них. Тогда при запуске моделей увеличится количество ошибок - данные будут совпадать случайным образом.
- Ошибки: confusion matrix для лучшей модели + комментарий. Диагностика на тесте: Confusion matrix помогает понять тип ошибок (FP/FN). Сохранение артефактов эксперимента в artifacts/figures/. Лучшая модель 'HistGradientBoosting' допускает умеренное количество ошибок.
- Интерпретация: permutation importance (top-10/15) + выводы: Permutation importance на тесте (top-15). Идея: перемешиваем один признак и смотрим, насколько падает качество. Чем больше падение, тем “важнее” признак для модели. В работе есть изображение артефакта HistGradientBoosting: permutation importance на тесте (top-15).

## 6. Conclusion

- Для улучшения работы модели дерева Decision Tree решений нужно уменьшать длину дерева.
- Для улучшения работы модели дерева Decision Tree решений нужно увеличивать количество точек внутри области.
- Для улучшения работы модели дерева Decision Tree решений нужно вводить ей штраф за сложность.
- В ансамбле деревьев Random Forest их большое количество снижает дисперсию.
- В ансамбле деревьев Random Forest ограничения глубины/листа помогают контролировать переобучение.
- Честный ML-протокол обеспечивает корректную работу моделей на тестовых данных.