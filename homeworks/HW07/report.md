# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): `S07-hw-dataset-01.csv`, `S07-hw-dataset-02.csv`, `S07-hw-dataset-03.csv`.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`.
- Размер: 12000 строк, 9 столбцов.
- Признаки: числовые типы признаков.
- Пропуски: нет пропусков.
- "Подлости" датасета: Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно "едут".

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`.
- Размер: 8000 строк, 4 столбца.
- Признаки: числовые типы признаков.
- Пропуски: нет пропусков.
- "Подлости" датасета: Нелинейная структура, выбросы, лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`.
- Размер: 15000 строк, 5 столбцов.
- Признаки: числовые типы признаков.
- Пропуски: нет пропусков.
- "Подлости" датасета: Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: были выполнены базовый препроцессинг StandardScaler (scaling) и опциональный этап PCA, pca_dim = 8.
- Поиск гиперпараметров:
  - Диапазон K для KMeans kmeans_ks = list(range(2, 21)), Сетка для DBSCAN: eps и min_samples. eps зависит от масштаба данных, после scaling обычно eps ~ 0.5..5. dbscan_eps = [1.5, 2.0, 2.5, 3.0, 3.5], dbscan_min_samples = [3, 5, 10].
  - чем руководствовались при выборе "лучшего": нужно минимум 2 кластера, нельзя, чтобы все точки были в одном кластере
- Метрики: silhouette требует, чтобы все кластеры имели >1 точки, в sklearn silhouette_score может падать, если какой-то кластер пуст/особый. silhouette (выше лучше), Davies-Bouldin (ниже лучше), Calinski-Harabasz (выше лучше).
- Визуализация: PCA(2D).

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`).
- DBSCAN (`eps`, `min_samples`, доля шума - метки non-noise).


## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: метод kmeans, параметры {'k': 2}, n_clusters: 2.
- Метрики (silhouette / DB / CH): silhouette: 0.522
  davies_bouldin: 0.685
  calinski_harabasz: 11787.0
  inertia: 48425.9
- Если был DBSCAN: noise_frac: 0.0  non-noise: 12000, не было шума.
- Коротко: решение выглдит разумным для этого датасета, при изменении параметров повышается доля шума, в данной ситуации лучше обойтись без шума, так как данные разделены с достаточно точным разделением на кластеры.

### 4.2 Dataset B

- Лучший метод и параметры: algo: kmeans
params: {'k': 2}
n_clusters: 2
- Метрики (silhouette / DB / CH): silhouette: 0.307
  davies_bouldin: 1.323
  calinski_harabasz: 3573.4
  inertia: 16588.5
- Если был DBSCAN: не было корректных конфигураций метода DBSCAN.
- Коротко: это решение разделяет данные датасета посередине, на положительную и отрицательную части.

### 4.3 Dataset C

- Лучший метод и параметры: algo: kmeans
params: {'k': 3}
n_clusters: 3
- Метрики (silhouette / DB / CH): silhouette: 0.316
  davies_bouldin: 1.158
  calinski_harabasz: 6957.2
  inertia: 31123.5
- Если был DBSCAN: не было корректных конфигураций метода DBSCAN.
- Коротко: метод kmeans разделяет данные тремя линиями на приблизительно равные части.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? 
- Ответ: при разном масштабировании признаков могут происходить сбои в кластеризации, вследствие чего решение будет некорректным. KMeans использует евклидово расстояние. Если один признак измеряется в условных “десятках”, а другой – в “тысячах”, то второй начнёт доминировать в расстоянии. 
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
- Ответ: алгоритм DBSCAN умеет находить кластеры произвольной формы, умеет помечать точки как шум (-1), вместо того чтобы “кластеризовать всё любой ценой”, не требует заранее задавать число кластеров K.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
- Ответ: масштабирование.

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
- Что получилось (в 3-6 строк)
- Вывод: устойчиво/неустойчиво и почему вы так считаете

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры: профили признаков - среднее.
- Среднее значения переменных внутри каждого кластера помогаюь определить характерные особенности каждого кластера.
- Так же для этих целей можно использовать медианные значения кластеров.
- В работе при такой интерпретации кластеров встретиись такие разделения, как: левая и правая половина системы координат, разделение на равные трети,  отдельные "облака" точек.

## 6. Conclusion

- Был освоен метод кластеризации KMeans.
- Был освоен метод кластеризации DBSCAN.
- Были получены навыки корректного препроцессинга для distance-based методов.
- Был освоен навык сравнения решения по внутренним метрикам (silhouette / Davies–Bouldin / Calinski–Harabasz) с пониманием ограничений этих метрик.
- Были получены навыки построения воспроизводимого корректного протокола для unsupervised-эксперимента и unsupervised-задачи.